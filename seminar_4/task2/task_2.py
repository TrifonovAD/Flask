# –ó–∞–¥–∞–Ω–∏–µ ‚Ññ1
# üêÄ –ù–∞–ø–∏—Å–∞—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–∑ 10 URL-
# –∞–¥—Ä–µ—Å–æ–≤ –∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –∫–∞–∂–¥–æ–≥–æ
# –∞–¥—Ä–µ—Å–∞.
# üêÄ –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω—É–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –∏—Ö –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ
# —Ñ–∞–π–ª—ã.
# üêÄ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ—Ü–µ—Å—Å—ã.

from requests import get
from time import sleep, time
from multiprocessing import Process

urls = ['https://www.google.ru/',
        'https://gb.ru/',
        'https://ya.ru/',
        'https://www.python.org/',
        'https://habr.com/ru/all/',
        'https://ru.wikipedia.org/',
        'https://ru.hexlet.io/',
        'https://megaseller.shop/',
        'https://linux.org',
        'https://metanit.com/',
        ]

def download(url):
    response = get(url)
    filename = 'proc_' + url.replace('https://', '').replace('.', '_').replace('/', '') + '.html'
    sleep(0.1)

    with open(filename, 'w', encoding='utf-8') as f:
        f.write(response.text)

procs = []

if __name__ == '__main__':
    for url in urls:
        proc = Process(target=download, args=[url], daemon=True)
        procs.append(proc)
        proc.start()

    for proc in procs:
        proc.join()



